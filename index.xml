<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据与方法</title>
    <link>https://IMchenjianqu.github.io/</link>
    <description>Recent content on 数据与方法</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sat, 19 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://IMchenjianqu.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>海藻生物量评估系统v1.0</title>
      <link>https://IMchenjianqu.github.io/%E6%95%B0%E6%8D%AE/%E6%B5%B7%E8%97%BB%E7%94%9F%E7%89%A9%E9%87%8F%E8%AF%84%E4%BC%B0%E7%B3%BB%E7%BB%9Fv1.0/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%95%B0%E6%8D%AE/%E6%B5%B7%E8%97%BB%E7%94%9F%E7%89%A9%E9%87%8F%E8%AF%84%E4%BC%B0%E7%B3%BB%E7%BB%9Fv1.0/</guid>
      <description>1.系统概述
1.1系统用途 “潮间带海藻生物量评估系统 v1.0”主要用于海洋调查中的潮间带调查，目标对象为大型海藻。主要应用RGB影像对潮间带海藻的生物量进行反演评估，减少海洋调查中投入大量的人力物力，同时减少由于大范围调查导致的生态破坏。该系统目前能进行反演的藻种主要有中国潮间带常见的三种优势藻种：孔石莼、鼠尾藻、羊栖菜。本系统将原位调查与机器学习方法进行结合，具有大众化、高效、环保的优点，且未来将继续探索其他海藻的反演模型，以期为潮间带调查提供新视角。
1.2功能概述 操作员可以通过RGB影像得知海藻生物量，而不需要在实地对海藻进行采集，也不需要对采集的海藻进行生物量的测定； 本系统不需要过高的硬件设施，具有大众化、高效的特点，操作人员只需按操作流程，将数据处理完毕即可使用。
1.3运行环境 硬件：Intel i5、16G内存、500G硬盘 操作系统：windows7、windows10等
1.4软件下载 当前版本由数据与方法 (imchenjianqu.github.io)向用户提供，用户可以在计算机的编译器中使用该系统
2.功能介绍
2.1RGB影像处理 可对目标影像进行光谱特征参数的提取（包括24个特征参数R、G、B、r、g、b、Exg、NGBVI、GBRI、VEGI、NPCI、RGBVI、RGRI、RGMPI、RBRI、RBMPI、RBMI、RGMI、RGPI、RBPI、GBPI、GBMI、VDVI、VARI）及获取灰度共生矩阵，获得纹理特征（包括27个特征参数Mean_R、Variance_R、Homogeneity_R、Contrast_R、Second Moment_R、Entropy_R、Correlation_R、ASM_R、IDM_R、Mean_G、Variance_G、Homogeneity_G、Contrast_G、Second Moment_G、Entropy_G、Correlation_G、ASM_G、IDM_G、Mean_B、Variance_B、Homogeneity_B、Contrast_B、Second Moment_B、Entropy_B、Correlation_B、ASM_B、IDM_B），并将结果输出到特定文件夹的csv文件中。 ![image](/biomass system/1.png)
2.2三个机器学习模型对生物量进行初步预测（网格搜索，CV=4） ![image](/biomass system/2.png) ![image](/biomass system/3.png)
2.3得到每个特征的贡献率及皮尔逊相关系数进行参数筛选 ![image](/biomass system/4.png) ![image](/biomass system/5.png)
2.4得到最优模型预测结果（孔石莼[R20.905]、鼠尾藻[R20.881]、羊栖菜[R20.821]） ![image](/biomass system/6.png) ![image](/biomass system/7.png) ![image](/biomass system/8.png)
3.版本更新
3.1更多的藻类模型及其他机器学习模型
3.2深度学习模型
下载地址：</description>
    </item>
    
    <item>
      <title>SVM、XGBoost及其融合模型（voting）在分类上的效果</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/svmxgboost%E5%8F%8A%E5%85%B6%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9E%8Bvoting%E5%9C%A8%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E6%95%88%E6%9E%9C/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/svmxgboost%E5%8F%8A%E5%85%B6%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9E%8Bvoting%E5%9C%A8%E5%88%86%E7%B1%BB%E4%B8%8A%E7%9A%84%E6%95%88%E6%9E%9C/</guid>
      <description>1.将光谱数据通过单因素方差分析后，选取P值较小（差异显著）的参数，每种藻选择前20个，一共三种藻，添加随机数random，打乱顺序 2.简单计算每个参数间的相关性，进行观察 3.计算两种模型的预测结果（左），计算两种模型通过voting算法融合的预测结果（右） 4.模型融合后，准确率显著提高
注 python代码如下：
# 数据处理 import numpy as np import pandas as pd # 可视化 import matplotlib.pyplot as plt import seaborn as sns # 机器学习 from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import StandardScaler from sklearn.metrics import accuracy_score from sklearn.model_selection import cross_val_score from sklearn.model_selection import KFold from sklearn.model_selection import GridSearchCV from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.svm import SVC from sklearn.tree import DecisionTreeClassifier from sklearn.</description>
    </item>
    
    <item>
      <title>海洋数据</title>
      <link>https://IMchenjianqu.github.io/%E6%95%B0%E6%8D%AE/%E6%B5%B7%E6%B4%8B%E6%95%B0%E6%8D%AE-%E6%9B%B4%E6%96%B0/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%95%B0%E6%8D%AE/%E6%B5%B7%E6%B4%8B%E6%95%B0%E6%8D%AE-%E6%9B%B4%E6%96%B0/</guid>
      <description>登陆 https://marine.copernicus.eu/寻找适合数据 （其中包括0.083°×0.083°分辨率的海水温度、盐度、流速，有效波高、风速等，0.5°×0.5°的叶绿素a、透明度等数据）
范围为global，时间为present(2000（不等）-present)
选择合适范围、时间、水层后，下载数据
若为模式数据model,分别通过以下IDL读取
 更新： 此前IDL中仅能读取流、盐、温、波高、风等数据 此处更新读取其他更多的数据（.nc），如浮游生物在海水中以碳的形式表达的质量含量（zooc，g m-2）、透明度&amp;hellip;
主要通过matlab进行半自动化提取
通过ncdisp对目标数据进行观察，具体思路是通过创建元胞组将经纬度读取成n×n的cell，再把z值（透明度，溶氧&amp;hellip;）同样读取成cell，再整合成n*n行，1列的cell，进行串联及输出 注 完整matlab代码如下
ncdisp(&amp;#39;1.nc&amp;#39;) %time = ncread(&amp;#39;1.nc&amp;#39;,&amp;#39;time&amp;#39;) x = ncread(&amp;#39;1.nc&amp;#39;,&amp;#39;latitude&amp;#39;); y = ncread(&amp;#39;1.nc&amp;#39;,&amp;#39;longitude&amp;#39;); %cont = 61*61; xy = cell(61) for m = 1:61 for n = 1:61 xy{m,n} = [y(m),x(n)] end end z = ncread(&amp;#39;1.nc&amp;#39;,&amp;#39;so&amp;#39;); xyz = cell(3721,1) for i = 1:61 for j = 1:61 xyz{61*(i-1)+j,1} = xy{i,j} end end so = (3721:1); for i = 1:61 for j = 1:61 so(61*(i-1)+j,1) = z(i,j) end end A = cell(3721,1) for cont = 1:3721 A{cont,1} = [xyz{cont,1},so(cont,1)] end %xlswrite(&amp;#39;salinity.</description>
    </item>
    
    <item>
      <title>灰度共生矩阵（GLCM）进行生物量回归</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E7%81%B0%E5%BA%A6%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5glcm%E8%BF%9B%E8%A1%8C%E7%94%9F%E7%89%A9%E9%87%8F%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E7%81%B0%E5%BA%A6%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5glcm%E8%BF%9B%E8%A1%8C%E7%94%9F%E7%89%A9%E9%87%8F%E5%9B%9E%E5%BD%92/</guid>
      <description>1.通过matlab选择不同滑动窗口，获得灰度共生矩阵，并求得常用的一些参数，如熵，能量，同质性等（11张照片，每张照片4个特征参数） 2.通过python建模（Random Forest）进行简单回归，得到预测生物量及R方 注： matlab主要应用graycomatrix及graycoprops
RF代码如下
import pandas as pd import numpy as np from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt #from sklearn import metrics from sklearn.metrics import r2_score from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import GridSearchCV seaweed_data = pd.read_csv(r&amp;#39;F:\biomass_feature.csv&amp;#39;, error_bad_lines=False) X = seaweed_data.drop([&amp;#34;biomass&amp;#34;], axis=1) y = seaweed_data[&amp;#34;biomass&amp;#34;] x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0) param_grid = { &amp;#39;n_estimators&amp;#39;: [5, 10, 20, 50, 100, 200],#决策树个数 &amp;#39;max_depth&amp;#39;: [3, 5, 7, 9],#最大树深 &amp;#39;max_features&amp;#39;: [0.</description>
    </item>
    
    <item>
      <title>坐标格式间批量转换</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E5%9D%90%E6%A0%87%E6%A0%BC%E5%BC%8F%E9%97%B4%E6%89%B9%E9%87%8F%E8%BD%AC%E6%8D%A2/</link>
      <pubDate>Sun, 04 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E5%9D%90%E6%A0%87%E6%A0%BC%E5%BC%8F%E9%97%B4%E6%89%B9%E9%87%8F%E8%BD%AC%E6%8D%A2/</guid>
      <description>通过百度坐标拾取、谷歌地球添加地标或其他方式获取的坐标点的格式不同（XXX.XXX°与XXX°XXX′XXX″），使用时需要转换，云端转换常常无法做到批量处理
 通过excel对坐标点进行批量转换
left与find函数截取“度”的数值
mid与find函数截取“分”的值并除以60
mid与find函数截取“秒”的值并除以3600
由于通过mid函数只能获取指定范围的切片，当实际切片与获得切片不符时，转换结果会出错
为得到更准确的结果，需要对特定位置进行修改，如上图，需要将“2”改为“4”（获取20.9），转换结果正确
转换为原始状态较为简单，只需使用text函数即可</description>
    </item>
    
    <item>
      <title>钢筋承力计算（悬臂梁）</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E9%92%A2%E7%AD%8B%E6%89%BF%E5%8A%9B%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E9%92%A2%E7%AD%8B%E6%89%BF%E5%8A%9B%E8%AE%A1%E7%AE%97/</guid>
      <description>1.分析结构，得到结构简图；进行受力分析，得到受力分析图；计算弯矩，得到弯矩图
2.计算物体所承受的弯矩
3.计算钢筋混凝土所能提供的弯矩
4.比较两者大小</description>
    </item>
    
    <item>
      <title>投票刷票器</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E6%8A%95%E7%A5%A8%E5%88%B7%E7%A5%A8%E5%99%A8/</link>
      <pubDate>Wed, 20 Jan 2021 20:46:53 +0800</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E6%8A%95%E7%A5%A8%E5%88%B7%E7%A5%A8%E5%99%A8/</guid>
      <description>投票刷票器，python，HTML
通过管理者工具，抓包查看post文件，获取投票服务器地址、投票人ID、协议头、动态参数位置
import urllib2,cookielib def vote(id=...%目标人员在服务器的ID); cookie = cookielib.CookieJar()%创建cookie对象 opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))%创建打开对象 urllib2.install_opener(opener)%将opener对象安装到全局 req = urllib2.Request(url=&amp;#39;http...&amp;#39;%当前网址url) html = urllib2.urlopen(req).read() a = html.find(&amp;#39;value=&amp;#34;&amp;#39;)%查找动态参数，亦可通过正则表达式获取 b = html.find(&amp;#39;&amp;#34;&amp;#39;,a+len(&amp;#39;value=&amp;#34;&amp;#39;)) token = html[a+len(&amp;#39;value=&amp;#34;&amp;#39;):b]%通过切片，获取动态参数 req = urllib2.Request(url=&amp;#39;http...&amp;#39;%投票服务器 data=&amp;#39;__RequestVerificationToken=%s&amp;amp;Chioce=%s&amp;amp;X...&amp;#39;)%输入动态参数与ID req.add_header(&amp;#34;User-Agent&amp;#34;,&amp;#34;...&amp;#34;)%协议头 req.add_header(&amp;#39;Referer&amp;#39;,&amp;#34;http...&amp;#34;)%投票服务器 html = urllib2.urlopen(req).read() for i in xrange(1000):%投1000票 vote() print(i) 可import threading模块进行多线程，提高投票速度
可同时投多人</description>
    </item>
    
    <item>
      <title>科学上网</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</link>
      <pubDate>Tue, 22 Dec 2020 14:46:53 +0800</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</guid>
      <description>最直接方式是，购买一台境外服务器，网上搜索资料，搭建梯子（服务器记得删除云镜，否则搭建成功后依旧无法访问访问你想要访问的网页），通过SSH即可使电脑和手机一起科学上网。但另一方面，这个开销巨大，即便购买域名来搭建自己网站，这同样是得不偿失。
 手机端 IPhone用户可通过app store登陆国外账户（美服：ID：milefenxiang@aliyun.com，密码：Ah336611,千万不能在app store意外的地方登陆，否则手机可能变砖） 然后下载小火箭，配置：类型选择&amp;quot;subscribe&amp;quot;，Method选择“salsa20” 更新&amp;mdash;连通性检查&amp;mdash;选择网速快的节点即可网上冲浪
 电脑端 使用谷歌插件HOXX（不知现在版本是否还可行，我自己一直不更新，用旧版本可免费） 登陆邮箱同步</description>
    </item>
    
    <item>
      <title>关于IMchenjianqu</title>
      <link>https://IMchenjianqu.github.io/about-hugo/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://IMchenjianqu.github.io/about-hugo/</guid>
      <description>常用数据及方法的聚合
It makes use of a variety of open source projects including:</description>
    </item>
    
    <item>
      <title>SVM实现（python）</title>
      <link>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/svm/</link>
      <pubDate>Sat, 12 Dec 2020 14:46:53 +0800</pubDate>
      
      <guid>https://IMchenjianqu.github.io/%E6%96%B9%E6%B3%95/svm/</guid>
      <description>通过python实现支持向量机实现——以高光谱数据为例
准备测试集数据后，运行训练模型，获得文件out_test_y.txt；准备训练集数据运行，训练函数，获得文件out_y_pred.txt。两文本文件中有对应的数据及分类号，通过对比，直观体现精度 通过运行Data Prepare准备训练集集数据
import pandas as pd import numpy as np import os import joblib def file_name(file_dir): #读取当前文件下的所有文件 for root, dirs, files in os.walk(file_dir): # print(root) #当前目录路径 # print(dirs) #当前路径下所有子目录 return files #当前路径下所有非目录子文件 def Data_prepare_non(label):#输入的是你的探测器的编号，非归一化。 file_list = file_name(&amp;#39;./data/&amp;#39;+label) print(file_list) hstack_list = [] for i in file_list: data = pd.read_excel(&amp;#39;./data/&amp;#39;+label+&amp;#39;/&amp;#39;+i) # max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))#归一化到（0，1）之间的函数 data_column = list(data.columns)#获取exexl中各个列名 hstack_list.append(np.array(data[[data_column[1]]]).reshape(1,-1)) x = hstack_list[0] for i in range(1,len(file_list)): x = np.</description>
    </item>
    
  </channel>
</rss>
